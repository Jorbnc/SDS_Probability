\subsubsection{Bayes' Rule}\topline
\begin{itemize}
^^I\item Consider a partition of $\Omega$ into $A_{i}$ disjoint events.
^^I\item We have an initial model or beliefs for $A_{i}$.
^^I\item We know how likely it is a particular event $B$ under each scenario, i.e. $P(B|A_{i})$.\\ \vspace{0.5mm}
^^I^^I^^I$\Blue{A_{i}} \xrightarrow[P(\Red{B}|\Blue{A_{i}})]{\text{model}} \Red{B}$ \vspace{0.5mm}
^^I\item Given that $B$ occurred, we can update our model: Analyze possible causes or most likely scenarios for $B$. \\ \vspace{0.5mm}
^^I^^I^^I$\Red{B} \xrightarrow[P(\Blue{A_{i}}|\Red{B})]{\text{inference}} \Blue{A_i}$ \vspace{0.5mm}
^^I\item In other words, we use inference to analyze how likely is a scenario $A_{i}$, given that $B$ occurred.
\end{itemize}
\vspace{0.5mm}
\begin{minipage}{0.34\linewidth}
^^I\centering
^^I\begin{tikzpicture}[scale=0.8]
^^I^^I\begin{scope}[line width=0.1mm]
^^I^^I^^I\fill [yellow!40!white, draw=black] (0, 0) rectangle (3, 2);
^^I^^I^^I\fill[draw=\ldraw, fill opacity=0.5, red!70!white] (1.6,0.9) ellipse (34pt and 22pt);
^^I^^I^^I\draw (0, 0.45) to [bend right=20] (1.5, 1);
^^I^^I^^I\draw (1.5, 1) to [bend right=20] (1.9, 2);
^^I^^I^^I\draw (1.5, 1) -- (2.2, 0);
^^I^^I^^I\node at (1, 1.1) {$\Blue{A_{1}} \cap \Red{B}$};
^^I^^I^^I\node at (2.05, 1.35) {$\Red{B}$};
^^I^^I^^I\node at (1.3, 0.4) {$\Blue{A_{2}} \cap \Red{B}$};
^^I^^I^^I\node at (2.2, 0.8) {$\Blue{A_{3}} \cap \Red{B}$};
^^I^^I^^I\node at (0.3, 1.75) {$\Blue{A_1}$};
^^I^^I^^I\node at (0.4, 0.2) {$\Blue{A_2}$};
^^I^^I^^I\node at (2.6, 1.70) {$\Blue{A_3}$};
^^I^^I\end{scope}
^^I\end{tikzpicture}
\end{minipage}%
\begin{minipage}{0.66\linewidth}
^^I\begin{align*}
^^I^^IP(A_{i}|B) &= \frac{P(A_{i} \cap B)}{P(B)} \\
^^I^^I^^I \Aboxed{P(A_{i}|B) &= \frac{P(A)P(B|A_{i})}{\sum_{j}P(A_j)P(B|A_j)}}
^^I\end{align*}
\end{minipage}\vspace{1.5mm}\\
Check the diagrams: \url{https://en.wikipedia.org/wiki/Bayes%27_theorem#Random_variables}
^^E^^L 
